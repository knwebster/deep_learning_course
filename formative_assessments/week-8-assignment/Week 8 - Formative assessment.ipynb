{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "## Formative assessment\n",
    "### Week 8: Normalising flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "In this notebook, you will write code to implement a complete RealNVP normalising flow model, including checkerboard and channel-wise masking, and combining all the components into a multiscale architecture. You will train the normalising flow on the CIFAR-10 dataset.\n",
    "\n",
    "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
    "\n",
    "`#### GRADED CELL ####`\n",
    "\n",
    "These cells require you to write your own code to complete them.\n",
    "\n",
    "#### Let's get started!\n",
    "\n",
    "We'll start by running some imports, and loading the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Layer, Input, Conv2D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<img src=\"figures/cifar10.png\" title=\"CIFAR-10\" style=\"width: 700px;\"/> \n",
    "\n",
    "#### The CIFAR-10 dataset\n",
    "In this assignment, you will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). This image dataset has 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. \n",
    "\n",
    "* A. Krizhevsky (2009), \"Learning Multiple Layers of Features from Tiny Images\", technical report.\n",
    "\n",
    "Your goal is to develop a RealNVP normalising flow generative model, trained on this dataset. This assignment will roughly follow the architecture described in the original RealNVP paper:\n",
    "\n",
    "* Dinh, L., Sohl-Dickstein, J. & Bengio, S. (2017), \"Density estimation using Real NVP\",  in *5th International Conference on Learning Representations, (ICLR)*, Toulon, France, April 24-26, 2017.\n",
    "\n",
    "An important conceptual point to bear in mind during the course of this assignment, is that we also follow the original paper by thinking of the forward transformation as acting on the input image. Note that this is in contrast to the convention for bijectors of using the forward transformation for sampling, and the inverse transformation for computing log probs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from keras.datasets\n",
    "\n",
    "(images_train, labels_train), (images_val, labels_val) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list for the labels\n",
    "\n",
    "word_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few images and labels\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "inx = np.random.choice(images_train.shape[0], 32, replace=False)\n",
    "for n, i in enumerate(inx):\n",
    "    ax = plt.subplot(4, 8, n+1)\n",
    "    plt.imshow(images_train[i])\n",
    "    plt.title(word_labels[int(np.squeeze(labels_train[i]))])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now write a `get_datasets` function to load the data into PyTorch DataLoaders, and preprocess the data ready for training.\n",
    "\n",
    "* The function takes arguments `images_train`, `images_val`, and `batch_size`\n",
    "* Your function should convert the image dtype to `float32`, rescale so the pixel values lie in the range `[0, 1]`\n",
    "* Create two `torch.utils.data.Dataset` objects, one for training and one for validation\n",
    "  * Only the images should be loaded into the Datasets; the labels will not be used\n",
    "  * The Datasets should return a tuple `(img, img)` containing two copies of the image\n",
    "* The corresponding DataLoaders should shuffle the training Dataset and batch both Datasets using the `batch_size` argument\n",
    "* Your function should return both DataLoaders in a tuple `(train_dl, valid_dl)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def get_datasets(images_train, images_val, batch_size):\n",
    "    \"\"\"\n",
    "    This function takes the training and validation images, as well as a\n",
    "    batch_size argument. It should load and preprocess the data as specified above.\n",
    "    Your function should then return the Datasets in the tuple (train_dl, valid_dl)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to create the Datasets\n",
    "\n",
    "batch_size = 64\n",
    "train_dl, valid_dl = get_datasets(images_train, images_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom model for log-scale and shift\n",
    "Recall the equations for the affine coupling layer:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left. \n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{z}_{1:d} &= &\\mathbf{x}_{1:d},\\\\\n",
    "\\mathbf{z}_{d+1:D} &=& \\mathbf{x}_{d+1:D}\\odot \\exp(s(\\mathbf{x}_{1:d})) + t(\\mathbf{x}_{1:d}).\n",
    "\\end{array}\n",
    "\\right\\}\\qquad\\text{forward pass}\n",
    "\\\\[1ex]\n",
    "\\left. \n",
    "\\begin{array}{rcl}\n",
    "\\mathbf{x}_{1:d} &=& \\mathbf{z}_{1:d},\\label{realnvp_inv_acl1}\\\\\n",
    "\\mathbf{x}_{d+1:D} &=& (\\mathbf{z}_{d+1:D} - t(\\mathbf{z}_{1:d})) \\odot \\exp(-s(\\mathbf{z}_{1:d})).\n",
    "\\end{array}\n",
    "\\right\\}\\qquad\\text{inverse pass}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We will use a custom CNN residual network model for the shift and log-scale parameters that are used in this layer bijector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now complete the following class to create a custom layer as the residual block for use in this custom model. \n",
    "\n",
    "* The class initializer takes `num_filters`, `kernel_size` and `l2reg_coeff` arguments, and optional keyword arguments\n",
    "  * Any keyword arguments should be passed up to the base class initializer\n",
    "  * The required arguments should be set as class attributes, to be available to other methods\n",
    "* The class should implement a `build` method, that creates the model layers\n",
    "  * There should be two `Conv2D` layers. The first has `num_filters` filters, and the second has the same number of filters as the layer inputs\n",
    "  * Both `Conv2D` layers should use the `kernel_size` argument to set the kernel size, and should use a ReLU activation and `\"SAME\"` padding\n",
    "  * Both `Conv2D` layers should also use $l^2$ kernel regularisation, using the `l2reg_coeff` argument\n",
    "  * This method should also create two `BatchNormalization` layers\n",
    "* In the `call` method, the layer inputs should be processed as follows:\n",
    "  * First, the inputs are passed through the first `Conv2D` layer (with `num_filters` filters)\n",
    "  * Then they are passed through a `BatchNormalization` layer\n",
    "  * Then they are processed by the other `Conv2D` layer, and then the other `BatchNormalization` layer\n",
    "  * Finally, this output should then be added to the original layer input and returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class Conv2DResidualBlock(Layer):\n",
    "    \n",
    "    def __init__(self, num_filters, kernel_size, l2reg_coeff, **kwargs):\n",
    "        \"\"\"\n",
    "        Class initializer takes kernel_size num_filters and l2reg_coeff as arguments, and \n",
    "        optional keyword arguments that should be passed to the base Layer class initializer.\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create residual block layers using your class\n",
    "\n",
    "resnet_block1 = Conv2DResidualBlock(64, (3, 3), 5e-5, name='resnet1')\n",
    "resnet_block2 = Conv2DResidualBlock(64, (3, 3), 5e-5, name='resnet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and call the first residual block\n",
    "\n",
    "resnet_block1(keras.random.normal((1, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and call the second residual block\n",
    "\n",
    "resnet_block2(keras.random.normal((1, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now complete the following `get_shift_and_log_scale_resnet` function that builds the full shift and log-scale network, using the `Conv2DResidualBlock` class above.\n",
    "\n",
    "* This function takes `input_shape`, `kernel_size` and `l2reg_coeff` as arguments, as well as `residual_blocks`, which is a list of `Conv2DResidualBlock` objects\n",
    "* The function should use the functional API to build the multi-output model\n",
    "* The model should use the `input_shape` in the function argument to set the shape in the `Input` layer\n",
    "* The inputs should be processed sequentially by the layers contained in the `residual_blocks` list\n",
    "* There should then be a final `Conv2D` layer that processes this output, using the `kernel_size` argument, and $l^2$ kernel regularization using `l2reg_coeff`\n",
    "  * This `Conv2D` layer should have twice as many filters as the input\n",
    "  * It should use `\"SAME\"` padding and have no activation function\n",
    "* The output of this layer should then be split into two equal-sized Tensors along the final channel axis. These two Tensors are the shift and log-scale Tensors, and should each have the same shape as the model input\n",
    "* Finally, you should then apply the `tanh` nonlinearity to the log_scale Tensor\n",
    "* The outputs to the model should be the list of Tensors `[shift, log_scale]`\n",
    "\n",
    "_Hint: use_ [`keras.ops.split`](https://keras.io/api/ops/numpy/#split-function) _to create the output Tensors_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_shift_and_log_scale_resnet(input_shape, kernel_size, l2reg_coeff, residual_blocks):\n",
    "    \"\"\"\n",
    "    This function should build the CNN shift and log-scale ResNet model according to the \n",
    "    above specification, using the functional API. The model should be multi-output, where\n",
    "    the output Tensors are [shift, log_scale].\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shift and log-scale model using your function\n",
    "\n",
    "shift_and_log_scale = get_shift_and_log_scale_resnet((6, 6, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block1, resnet_block2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "shift_and_log_scale.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output shapes are as expected\n",
    "\n",
    "print(shift_and_log_scale(keras.random.normal((1, 6, 6, 3)))[0].shape)\n",
    "print(shift_and_log_scale(keras.random.normal((1, 6, 6, 3)))[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary masks\n",
    "\n",
    "Now that the shift and log-scale model code is complete, you can use it in the implementation of the affine coupling layer. Recall that the affine coupling layer transformations can be rewritten in the following form, using a binary mask $b$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{z} &= b\\odot \\mathbf{x} + (1-b)\\odot(\\mathbf{x}\\odot \\exp(s(b\\odot \\mathbf{x})) + t(b\\odot\\mathbf{x})) & \\text{(forward pass)}\\\\\n",
    "\\mathbf{x} &= b\\odot \\mathbf{z} + (1-b)\\odot((\\mathbf{z}-t(b\\odot\\mathbf{z}))\\odot \\exp(-s(b\\odot \\mathbf{z}))) & \\text{(inverse pass)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The following two functions will be used to create the binary masks in this layer.\n",
    "\n",
    "First, you should complete the following function that builds the channel-wise binary mask. \n",
    "\n",
    "* This function takes a single integer `num_channels` as an input\n",
    "* You can assume that `num_channels` is even\n",
    "* The function should return a rank-3 Tensor with singleton entries for height and width dimensions\n",
    "* In the channel axis, the first `num_channels // 2` entries should be zero, and the final `num_channels // 2` entries should be one\n",
    "* The `dtype` of the returned Tensor should be `float32`\n",
    "* The function should return the binary mask Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def channel_binary_mask(num_channels):\n",
    "    \"\"\"\n",
    "    This function should build and return the channel-wise binary mask as described above,\n",
    "    with zeros for the first half of the channels, and ones for the remainder.\n",
    "    Your function should return the binary mask Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to see an example channel-wise binary mask\n",
    "\n",
    "channel_binary_mask(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates the checkerboard binary mask.\n",
    "\n",
    "* The function takes `shape` as an input, which is a integer tuple of length 2, corresponding to the height and width dimensions\n",
    "* You can assume both height and width dimensions are even integers\n",
    "* The function should return a rank-3 Tensor with a singleton entry in the channel dimension\n",
    "* In the spatial dimensions, the entry at index `[0, 0]` should be zero. The remaining entries should be filled with ones and zeros in a checkerboard pattern\n",
    "* The `dtype` of the returned Tensor should be `tf.float32`\n",
    "* The function should return the binary mask Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def checkerboard_binary_mask(shape):\n",
    "    \"\"\"\n",
    "    This function should build and return the spatial checkerboard binary mask as \n",
    "    described above, with a zero in the [0, 0] entry in the spatial dimensions.\n",
    "    Your function should return the binary mask Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to see an example checkerboard binary mask\n",
    "\n",
    "ops.squeeze(checkerboard_binary_mask((6, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affine coupling layer\n",
    "\n",
    "The following is the same class that we implemented in this week's coding tutorial (with the minor modification of adding the `training` keyword argument for use with the `BatchNormalization` layers). It will work with either of the binary masks above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(Layer):\n",
    "\n",
    "    def __init__(self, shift_and_log_scale_fn, mask, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.shift_and_log_scale_fn = shift_and_log_scale_fn\n",
    "        self.b = ops.cast(mask, 'float32')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.event_dims = list(range(1, len(input_shape)))\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        t, log_s = self.shift_and_log_scale_fn(self.b * x, training=training)\n",
    "        z = self.b * x + (1 - self.b) * (x * ops.exp(log_s) + t) \n",
    "        \n",
    "        self.add_loss(-ops.mean(ops.sum(log_s * (1 - self.b), axis=self.event_dims)))\n",
    "        return z\n",
    "\n",
    "    def inverse(self, z, training=None):\n",
    "        t, log_s = self.shift_and_log_scale_fn(self.b * z, training=training)\n",
    "        x = self.b * z + (1 - self.b) * ((z - t) * ops.exp(-log_s))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an affine coupling layer with a checkerboard mask\n",
    "\n",
    "mask = checkerboard_binary_mask((6, 6))\n",
    "affine_coupling_layer = AffineCouplingLayer(shift_and_log_scale, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View an example layer output - look at only one channel dimension for easier viewing\n",
    "\n",
    "output = affine_coupling_layer(ops.ones((1, 6, 6, 3)))\n",
    "print(ops.squeeze(output)[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, you should find that the unmasked elements (entries where the mask is equal to one) are unchanged.\n",
    "\n",
    "#### Combining the affine coupling layers\n",
    "\n",
    "Recall that the affine coupling layers are combined into groups of 3 or 4 in the RealNVP architecture. Within each group, successive affine coupling layers are applied with alternating masks.\n",
    "\n",
    "You should now complete the following `AffineCouplingLayerBlock` custom layer to build one of these blocks. \n",
    "\n",
    "* The class initialiser takes `shift_and_log_scale_fns` and `mask` as arguments\n",
    "* The `shift_and_log_scale_fns` is a list or tuple of shift and log scale objects (as used in the `AffineCouplingLayer` above)\n",
    "* The `mask` argument is either a channel-wise or checkerboard mask Tensor\n",
    "* The layer should consist of successive `AffineCouplingLayer` objects chained together\n",
    "  * The first affine coupling layer should use the mask passed in the `mask` argument\n",
    "  * Following affine coupling layers should use alternating masks (of the same type)\n",
    "* As well as implementing the `call` method, your layer should also implement an `inverse` method for the backward pass through the affine coupling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "class AffineCouplingLayerBlock(Layer):\n",
    "\n",
    "    def __init__(self, shift_and_log_scale_fns, mask, **kwargs):\n",
    "        \"\"\"\n",
    "        Class initializer takes shift_and_log_scale_fns and mask as arguments, and \n",
    "        optional keyword arguments that should be passed to the base Layer class initializer.\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an affine coupling layer block\n",
    "\n",
    "resnet_block1 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block2 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_1 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block1, resnet_block2])\n",
    "\n",
    "resnet_block3 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block4 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_2 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block3, resnet_block4])\n",
    "\n",
    "resnet_block5 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block6 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_3 = get_shift_and_log_scale_resnet((32, 32, 3), (3, 3), 5e-5, \n",
    "                                                     [resnet_block5, resnet_block6])\n",
    "\n",
    "mask = checkerboard_binary_mask((32, 32))\n",
    "\n",
    "acl_block_1 = AffineCouplingLayerBlock([shift_and_log_scale_1, shift_and_log_scale_2, shift_and_log_scale_3], mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The squeeze operation\n",
    "\n",
    "In the RealNVP architecture, after an affine coupling layer block with checkerboard masking (as above), there is a squeeze operation, where the spatial dimensions of the layer are divided into $2\\times 2\\times c$ subsquares, and reshaped into $1\\times 1\\times 4c$.\n",
    "\n",
    "The squeezing operation is also a bijective operation. The `call` method has been completed for you in the custom `Squeeze` layer below. Note that the log Jacobian determinant of the squeeze operation is zero, so there is no contribution from this layer to the negative log-likelihood loss.\n",
    "\n",
    "You should now complete the `inverse` method in the custom layer below. As with the `AffineCouplingLayer` class, this method should compute the inverse of the `call` computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class Squeeze(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        input_shape = ops.shape(x)\n",
    "        batch_size, height, width, channels = input_shape\n",
    "        h = ops.reshape(x, (batch_size, height // 2, 2, width // 2, 2, channels))\n",
    "        h = ops.transpose(h, axes=[0, 1, 3, 2, 4, 5])\n",
    "        z = ops.reshape(h, (batch_size, height // 2, width // 2, 4 * channels))\n",
    "        return z\n",
    "\n",
    "    def inverse(self, z):\n",
    "        \"\"\"\n",
    "        This method should compute the inverse of the call method,\n",
    "        as described above.\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Squeeze bijector\n",
    "\n",
    "squeeze = Squeeze()\n",
    "squeeze(ops.ones((10, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the inverse operation\n",
    "\n",
    "squeeze.inverse(ops.ones((10, 4, 4, 96))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiscale architecture\n",
    "\n",
    "You are now ready to bring all of the components together in the complete multiscale architecture. The RealNVP model that we will build will factor out latent variables to downscale the input only once. This model is visualised in the following diagram:\n",
    "\n",
    "<img src=\"figures/realnvp_model.png\" alt=\"RealNVP model\" style=\"width: 800px;\"/>\n",
    "\n",
    "We have already instantiated the first of these affine couple layer blocks above. The following two cells instantiate the remaining two blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the second affine coupling layer block\n",
    "\n",
    "resnet_block7 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block8 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_4 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block7, resnet_block8])\n",
    "\n",
    "resnet_block9 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block10 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_5 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block9, resnet_block10])\n",
    "\n",
    "resnet_block11 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block12 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_6 = get_shift_and_log_scale_resnet((16, 16, 12), (3, 3), 5e-5, \n",
    "                                                     [resnet_block11, resnet_block12])\n",
    "\n",
    "mask = channel_binary_mask(12)\n",
    "\n",
    "acl_block_2 = AffineCouplingLayerBlock([shift_and_log_scale_4, shift_and_log_scale_5, shift_and_log_scale_6], mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the third affine coupling layer block\n",
    "\n",
    "resnet_block13 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block14 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_7 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block13, resnet_block14])\n",
    "\n",
    "resnet_block15 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block16 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_8 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block15, resnet_block16])\n",
    "\n",
    "resnet_block17 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block18 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_9 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                     [resnet_block17, resnet_block18])\n",
    "\n",
    "resnet_block19 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "resnet_block20 = Conv2DResidualBlock(64, (3, 3), 5e-5)\n",
    "shift_and_log_scale_10 = get_shift_and_log_scale_resnet((16, 16, 6), (3, 3), 5e-5, \n",
    "                                                        [resnet_block19, resnet_block20])\n",
    "\n",
    "mask = checkerboard_binary_mask((16, 16))\n",
    "\n",
    "acl_block_3 = AffineCouplingLayerBlock([shift_and_log_scale_7, shift_and_log_scale_8, \n",
    "                                        shift_and_log_scale_9, shift_and_log_scale_10],\n",
    "                                       mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now implement the multiscale architecture in the following custom layer. This layer should be constructed to be able to operate on a batch of Tensors of shape `(B, H, W, C)`, with the only assumption being that `H` and `W` are both even.\n",
    "\n",
    "* The initializer takes the three affine coupling layer blocks that are part of the above architecture:\n",
    "  * `acl_block_1` is a block with 3 affine coupling layers with checkerboard masking\n",
    "  * `acl_block_2` is a block with 3 affine coupling layers with channel masking\n",
    "  * `acl_block_3` is n block with 4 affine coupling layers with checkerboard masking\n",
    "* You should implement the `call` and `inverse` methods\n",
    "* The forward transformation should operate on the inputs as depicted above:\n",
    "  * It should pass the inputs through the first ACL block, a `Squeeze` operation, and then the second ACL block\n",
    "  * It should then split the Tensor in half along the channel axis\n",
    "  * The first half of the channel dimensions should be used as latent variables. Call this $\\mathbf{z}^{(1)}$\n",
    "  * The second half of the channel dimensions (call this $\\mathbf{h}^{(1)}$) should be further processed through the third ACL block to produce $\\mathbf{z}^{(2)}$\n",
    "  * The final latent variable $\\mathbf{z} = (\\mathbf{z}^{(1)}, \\mathbf{z}^{(2)})$ should be concatenated along the channel dimension. This should be returned by the `call` method\n",
    "* The `inverse` method should perform precisely the inverse of the `call` method\n",
    "  \n",
    "_Hint: use_ `keras.ops.split` _and_ `keras.ops.concatenate` _to factor out (and recombine) latent variables in the forward and inverse passes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class name or provided methods and signatures.\n",
    "\n",
    "class RealNVPMultiScale(Layer):\n",
    "    \n",
    "    def __init__(self, acl_block_1, acl_block_2, acl_block_3, **kwargs):\n",
    "        \"\"\"\n",
    "        The initializer takes three instances of the AffineCouplingLayerBlock class.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        \"\"\"\n",
    "        This function computes the forward transformation as described above.\n",
    "        It takes an input image batch x, and returns a latent variable batch z.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inverse(self, z, training=None):\n",
    "        \"\"\"\n",
    "        This function computes the inverse transformation as described above.\n",
    "        It takes a latent variable batch z, and returns an input image batch x.\n",
    "        \"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the RealNVP model\n",
    "\n",
    "realnvp = RealNVPMultiScale(acl_block_1, acl_block_2, acl_block_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing layer\n",
    "\n",
    "We will also preprocess the image data before sending it through the RealNVP model. To do this, for a Tensor $\\mathbf{x}$ of pixel values in $[0, 1]^D$, we transform $\\mathbf{x}$ according to the following (all operations performed elementwise):\n",
    "\n",
    "$$\n",
    "T(\\mathbf{x}) = \\text{logit}\\left(\\alpha + (1 - 2\\alpha)\\mathbf{x}\\right),\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is a parameter, and the logit function is the inverse of the sigmoid function, which is given by \n",
    "\n",
    "$$\n",
    "\\text{logit}(p) = \\log (p) - \\log (1 - p).\n",
    "$$\n",
    "\n",
    "You should now complete the following class to construct this invertible layer.\n",
    "\n",
    "* The initializer takes the parameter `alpha` as an input, which you can assume to take a small positive value ($\\ll0.5$)\n",
    "* The layer's `call` method should compute $T(\\mathbf{x})$ in the forward pass\n",
    "* You should also implement an `inverse` method, which computes the inverse of the `call` method\n",
    "* This layer is a preprocessing step and not part of the normalising flow itself, so the layer should not add a log Jacobian determinant loss contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "class PreProcessor(Layer):\n",
    "    \"\"\"\n",
    "    Extra data preprocessing step implemented as a custom Layer. The layer\n",
    "    should implement the __init__, call and inverse methods as described above.\n",
    "    \"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the preprocess bijector\n",
    "\n",
    "preprocess = PreProcessor(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and train the RealNVP model\n",
    "\n",
    "The following is the same custom loss function that we implemented in this week's coding tutorial. We will make use of it again to implement the latent space distribution loss term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom loss function\n",
    "\n",
    "def normal_pdf_loss(y_true, y_pred):\n",
    "    event_dims = list(range(1, len(y_pred.shape)))\n",
    "    const = 0.5 * ops.log(2. * np.pi)\n",
    "    return ops.sum(const + ops.square(y_pred)/2., axis=event_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model for training\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "h = preprocess(inputs)\n",
    "outputs = realnvp(h)\n",
    "realnvp_model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "realnvp_model.compile(loss=normal_pdf_loss, optimizer=optimizer)\n",
    "realnvp_model.fit(train_dl, validation_data=valid_dl, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the model\n",
    "\n",
    "n_images = 12\n",
    "\n",
    "h = keras.random.normal((n_images, 16, 16, 12))\n",
    "for layer in reversed(realnvp_model.layers[1:]):\n",
    "    h = layer.inverse(h)\n",
    "    \n",
    "samples = ops.convert_to_numpy(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the samples\n",
    "\n",
    "f, axs = plt.subplots(2, n_images // 2, figsize=(17, 6))\n",
    "for k, image in enumerate(samples):\n",
    "    i = k % 2\n",
    "    j = k // 2\n",
    "    axs[i, j].imshow(np.clip(image, 0., 1.))\n",
    "    axs[i, j].axis('off')\n",
    "f.subplots_adjust(wspace=0.03, hspace=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this week's assignment! In this assignment you have developed a full implementation of the RealNVP architecture, including the affine coupling layers with channel-wise and checkerboard masking, CNN ResNet networks for the shift and log scale functions, the squeeze operation and multiscale architecture. For optimal performance, the model should be larger and trained for longer. The architecture in the original paper also contains some additional features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
